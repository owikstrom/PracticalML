---
title: "Untitled"
author: "Olov Wikstrom"
date: "6/3/2020"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
```

## Data Prep & Exploratory Data Analysis
```{r import, cache=TRUE}
fileTrain <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileTest <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if(!file.exists(basename(fileTrain))){
  download.file(fileTrain, basename(fileTrain))
}

if(!file.exists(basename(fileTest))){
  download.file(fileTest, basename(fileTest))
}

train <- read.csv(basename(fileTrain))
test <- read.csv(basename(fileTest))
```
The imported files have 160 variables and 20k observations for the training set vs 20 for the test set. The dataset contains many errors and missing data. 

matrix
test 
covariation

Imputing values

pairs(classe~., data=train[,1:8])
```{r datacheck, cache=TRUE}
sum(complete.cases(train))/length(train$X)
```
With only 2% complete cases, lets check if the errors are localized at certain variables. Looking at the raw .csv files the errors seem to be one of 3 cases, which are stored in errorStrings.

```{r wrangling, cache=TRUE}
# Prepare and apply to extract the columns with large proportions of NA
errorStrings = c("NA", "#DIV/0!", "","NULL")
error_count <-sapply(train[,8:159], function(x) sum(length(which(x %in% errorStrings | is.na(x)))))
summary(error_count)
hist(error_count)
errCols <-names(error_count[error_count>5000])

# Remove those cols
test <- test %>% select(-errCols)
train <- train %>% select(-errCols)
```
We're left with a much more manageable dataset. First 7 variables most likely also aren't relevant.


```{r}
train <- train %>% mutate(user_name=factor(user_name))

```

## Method choice
Applying what we learnt from the course, it will be interesting to see the efficiency of the different models. 

Preprocessing?


LM 
rf
boosting
lda
gbm boosting with trees
gam? generalized additive model
pca
lasso


combining with RF

```{r pressure, echo=FALSE}
```

